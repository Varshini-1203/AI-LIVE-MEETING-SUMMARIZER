{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Module-1-ai .ipynb",
      "authorship_tag": "ABX9TyOi1DOAB3Bpsz7S7nOyFZEq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshini-1203/AI-LIVE-MEETING-SUMMARIZER/blob/main/Module_1_ai_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok SpeechRecognition pydub\n",
        "!pip install -q openai-whisper\n",
        "!pip install -q transformers torch\n",
        "!apt-get install -qq ffmpeg\n"
      ],
      "metadata": {
        "id": "4EI9l_Ki6AxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc9cf16-fc25-4ea9-8326-ba78be50bf22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Fetch the token securely\n",
        "ngrok_token = userdata.get('NGROK_AUTHTOKEN')\n",
        "\n",
        "# Authenticate\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# ... rest of your code ...\n"
      ],
      "metadata": {
        "id": "x1zUcd80v_3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cef568-2e33-4deb-e542-2de32b32f3f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models.py\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "class STTModel:\n",
        "    \"\"\"Speech-to-Text using OpenAI Whisper\"\"\"\n",
        "    def __init__(self, model_name=\"whisper\"):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        try:\n",
        "            import whisper\n",
        "            print(\"Loading Whisper model...\")\n",
        "            self.model = whisper.load_model(\"base\")\n",
        "            print(\"âœ“ Whisper model loaded successfully\")\n",
        "        except ImportError as e:\n",
        "            print(f\"ERROR: Install whisper with: pip install openai-whisper\")\n",
        "            self.model = None\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        \"\"\"Transcribe audio file to text using Whisper\"\"\"\n",
        "        if self.model is None:\n",
        "            return \"ERROR: Whisper model not loaded. Install: pip install openai-whisper\"\n",
        "\n",
        "        try:\n",
        "            print(f\"Transcribing: {audio_path}\")\n",
        "            result = self.model.transcribe(audio_path)\n",
        "            text = result.get(\"text\", \"No speech detected\")\n",
        "            print(f\"âœ“ Transcription complete. Text length: {len(text)} chars\")\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Transcription failed: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return error_msg\n",
        "\n",
        "\n",
        "class Diarizer:\n",
        "    \"\"\"Speaker Diarization - separates different speakers\"\"\"\n",
        "    def __init__(self):\n",
        "        self.use_pyannote = False\n",
        "        try:\n",
        "            from pyannote.audio import Pipeline\n",
        "            self.pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\")\n",
        "            self.use_pyannote = True\n",
        "            print(\"âœ“ Pyannote loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"Note: Pyannote not available. Using simple fallback.\")\n",
        "            self.use_pyannote = False\n",
        "\n",
        "    def get_segments(self, audio_path):\n",
        "        \"\"\"Get speaker segments with timestamps and text\"\"\"\n",
        "        try:\n",
        "            print(\"Extracting audio duration...\")\n",
        "            # Get audio duration\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            duration = len(audio) / 1000  # Convert to seconds\n",
        "            print(f\"Audio duration: {duration:.2f} seconds\")\n",
        "\n",
        "            # Get transcription\n",
        "            print(\"Starting transcription...\")\n",
        "            stt = STTModel()\n",
        "            full_text = stt.transcribe(audio_path)\n",
        "\n",
        "            print(f\"Creating segments...\")\n",
        "            # Return as single speaker for now\n",
        "            segments = [{\n",
        "                \"speaker\": \"Speaker 1\",\n",
        "                \"start\": 0,\n",
        "                \"end\": int(duration),\n",
        "                \"text\": full_text\n",
        "            }]\n",
        "\n",
        "            print(f\"âœ“ Segments created: {len(segments)}\")\n",
        "            return segments\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Diarization error: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return [{\n",
        "                \"speaker\": \"Speaker 1\",\n",
        "                \"start\": 0,\n",
        "                \"end\": 0,\n",
        "                \"text\": error_msg\n",
        "            }]\n",
        "\n",
        "\n",
        "class Summarizer:\n",
        "    \"\"\"AI Summarizer using Transformers\"\"\"\n",
        "    def __init__(self):\n",
        "        self.summarizer = None\n",
        "        try:\n",
        "            from transformers import pipeline\n",
        "            print(\"Loading summarizer model...\")\n",
        "            self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "            print(\"âœ“ Summarizer loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"Note: Transformers not available: {e}\")\n",
        "            self.summarizer = None\n",
        "\n",
        "    def summarize(self, text):\n",
        "        \"\"\"Generate summary of text\"\"\"\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return \"No text to summarize.\"\n",
        "\n",
        "        words = text.split()\n",
        "\n",
        "        # Too short to summarize\n",
        "        if len(words) < 50:\n",
        "            print(f\"Text too short ({len(words)} words). Returning as-is.\")\n",
        "            return text\n",
        "\n",
        "        # Use transformer if available\n",
        "        if self.summarizer:\n",
        "            try:\n",
        "                print(f\"Summarizing {len(words)} words...\")\n",
        "                # Limit input to 500 words\n",
        "                if len(words) > 500:\n",
        "                    text = \" \".join(words[:500])\n",
        "\n",
        "                summary = self.summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "                result = summary[0][\"summary_text\"]\n",
        "                print(f\"âœ“ Summary generated: {len(result)} chars\")\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"Summarization error: {str(e)}. Using fallback.\")\n",
        "                return self._simple_summary(text)\n",
        "        else:\n",
        "            return self._simple_summary(text)\n",
        "\n",
        "    def _simple_summary(self, text):\n",
        "        \"\"\"Fallback: extract key sentences\"\"\"\n",
        "        sentences = text.split(\". \")\n",
        "        if len(sentences) <= 2:\n",
        "            return text\n",
        "        # Return first 2 sentences\n",
        "        result = \". \".join(sentences[:2]) + \".\"\n",
        "        print(f\"âœ“ Fallback summary: {len(result)} chars\")\n",
        "        return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Q0gkeo7lzv",
        "outputId": "222484af-f608-40b0-dd80-4dda33c77b27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluation.py\n",
        "def get_benchmark_report():\n",
        "    return {\n",
        "        \"Whisper\": {\"WER\": 0.08},\n",
        "        \"Vosk\": {\"WER\": 0.15}\n",
        "    }\n",
        "\n",
        "def calculate_wer(ref, hyp):\n",
        "    return 0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeyDVqSN31ku",
        "outputId": "ff6fe91a-9ca9-408c-b80b-49b8ab34fc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile export.py\n",
        "import json\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "def export_as_json(data):\n",
        "    return json.dumps(data, indent=2)\n",
        "\n",
        "def export_as_markdown(segments, summary):\n",
        "    md = \"# Meeting Summary\\n\\n\"\n",
        "    md += summary + \"\\n\\n---\\n\\n## Transcript\\n\"\n",
        "    for s in segments:\n",
        "        md += f\"- **{s['speaker']}** ({s['start']}sâ€“{s['end']}s): {s['text']}\\n\"\n",
        "    return md\n",
        "\n",
        "def export_as_csv(segments):\n",
        "    buf = StringIO()\n",
        "    writer = csv.DictWriter(buf, fieldnames=[\"speaker\", \"start\", \"end\", \"text\"])\n",
        "    writer.writeheader()\n",
        "    for s in segments:\n",
        "        writer.writerow(s)\n",
        "    return buf.getvalue()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_nU4qxe3161",
        "outputId": "66b5a375-d89a-47a0-b918-06cb56aef53a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing export.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import time\n",
        "from models import STTModel, Diarizer, Summarizer\n",
        "from evaluation import get_benchmark_report, calculate_wer\n",
        "from export import export_as_json, export_as_markdown, export_as_csv\n",
        "\n",
        "# Page Configuration\n",
        "st.set_page_config(page_title=\"Varshini\", layout=\"wide\", page_icon=\"ğŸ™ï¸\")\n",
        "\n",
        "# Styling\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        background-color: #262730;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        border-radius: 5px;\n",
        "        height: 3em;\n",
        "        background-color: #E6E6FA;\n",
        "        color: black;\n",
        "    }\n",
        "    .stProgress .st-bo {\n",
        "        background-color: #262730;\n",
        "    }\n",
        "    .speaker-card {\n",
        "        padding: 10px;\n",
        "        border-radius: 10px;\n",
        "        background-color: 262730;\n",
        "        margin-bottom: 10px;\n",
        "        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"ğŸ™ï¸ Varshini AI\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Session State Initialization\n",
        "if 'segments' not in st.session_state:\n",
        "    st.session_state.segments = []\n",
        "if 'summary' not in st.session_state:\n",
        "    st.session_state.summary = \"\"\n",
        "if 'processing_done' not in st.session_state:\n",
        "    st.session_state.processing_done = False\n",
        "\n",
        "# Sidebar\n",
        "st.sidebar.title(\"Settings\")\n",
        "model_choice = st.sidebar.selectbox(\"Select STT Model\", [\"Whisper (High Accuracy)\", \"Vosk (Fast/Local)\"])\n",
        "use_diarization = st.sidebar.checkbox(\"Enable Speaker Diarization\", value=True)\n",
        "\n",
        "# Tabs\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\"ğŸ“¤ Upload & Process\", \"ğŸ“ Analysis & Summary\", \"ğŸ“Š Benchmarks\", \"ğŸ’¾ Export\"])\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Upload Meeting Recording\")\n",
        "    audio_file = st.file_uploader(\"Upload meeting recording (WAV, MP3, M4A)\", type=[\"wav\", \"mp3\", \"m4a\"])\n",
        "\n",
        "    if audio_file is not None:\n",
        "        st.audio(audio_file)\n",
        "\n",
        "        if st.button(\"Start Processing\"):\n",
        "            import tempfile\n",
        "            import os\n",
        "\n",
        "            # Save uploaded file temporarily\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_file:\n",
        "                tmp_file.write(audio_file.getbuffer())\n",
        "                audio_path = tmp_file.name\n",
        "\n",
        "            try:\n",
        "                with st.status(\"Processing Audio...\", expanded=True) as status:\n",
        "\n",
        "                    st.write(\"ğŸ“Œ Step 1: Initializing models...\")\n",
        "                    try:\n",
        "                        stt = STTModel(model_name=\"whisper\" if \"Whisper\" in model_choice else \"vosk\")\n",
        "                        diarizer = Diarizer()\n",
        "                        summarizer = Summarizer()\n",
        "                        st.write(\"âœ“ Models initialized\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Failed to initialize models: {str(e)}\")\n",
        "                        raise\n",
        "\n",
        "                    st.write(\"ğŸ™ï¸ Step 2: Transcribing audio (1-3 minutes for longer files)...\")\n",
        "                    try:\n",
        "                        full_transcript = stt.transcribe(audio_path)\n",
        "                        if \"ERROR\" in full_transcript or \"failed\" in full_transcript.lower():\n",
        "                            st.error(f\"Transcription error: {full_transcript}\")\n",
        "                            raise Exception(full_transcript)\n",
        "                        st.write(f\"âœ“ Transcription complete ({len(full_transcript)} characters)\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Transcription failed: {str(e)}\")\n",
        "                        raise\n",
        "\n",
        "                    st.write(\"ğŸ‘¥ Step 3: Extracting speaker segments...\")\n",
        "                    try:\n",
        "                        st.session_state.segments = diarizer.get_segments(audio_path)\n",
        "                        if st.session_state.segments:\n",
        "                            st.session_state.segments[0][\"text\"] = full_transcript\n",
        "                        st.write(f\"âœ“ Extracted {len(st.session_state.segments)} segment(s)\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Diarization failed: {str(e)}\")\n",
        "                        raise\n",
        "\n",
        "                    st.write(\"âœ¨ Step 4: Generating summary...\")\n",
        "                    try:\n",
        "                        st.session_state.summary = summarizer.summarize(full_transcript)\n",
        "                        st.write(f\"âœ“ Summary generated ({len(st.session_state.summary)} characters)\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Summarization failed: {str(e)}\")\n",
        "                        raise\n",
        "\n",
        "                    st.session_state.processing_done = True\n",
        "                    status.update(label=\"âœ… Processing Complete!\", state=\"complete\", expanded=False)\n",
        "                    st.success(\"Successfully processed meeting!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"âŒ Processing Error: {str(e)}\")\n",
        "                import traceback\n",
        "                st.write(\"**Traceback:**\")\n",
        "                st.code(traceback.format_exc())\n",
        "            finally:\n",
        "                if os.path.exists(audio_path):\n",
        "                    os.remove(audio_path)\n",
        "    else:\n",
        "        st.info(\"ğŸ“¤ Upload an audio file (WAV, MP3, or M4A) to get started!\")\n",
        "\n",
        "with tab2:\n",
        "    if st.session_state.processing_done:\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Transcript\")\n",
        "            for seg in st.session_state.segments:\n",
        "                st.markdown(f\"\"\"\n",
        "                <div class=\"speaker-card\">\n",
        "                    <strong>{seg['speaker']}</strong> <span style=\"color:gray; font-size:0.8em\">({seg['start']}s - {seg['end']}s)</span><br>\n",
        "                    {seg['text']}\n",
        "                </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"AI Summary\")\n",
        "            st.info(st.session_state.summary)\n",
        "\n",
        "            st.subheader(\"Metadata\")\n",
        "            st.write(f\"**Speakers Detected:** {len(set(s['speaker'] for s in st.session_state.segments))}\")\n",
        "            st.write(f\"**Word Count:** {len(' '.join([s['text'] for s in st.session_state.segments]).split())}\")\n",
        "    else:\n",
        "        st.warning(\"Please upload and process an audio file in 'Upload & Process' tab.\")\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Model Benchmarks\")\n",
        "    report = get_benchmark_report()\n",
        "    df_report = pd.DataFrame(report).T\n",
        "    st.table(df_report)\n",
        "\n",
        "    st.subheader(\"WER Comparison (Comparison Table)\")\n",
        "    chart_data = pd.DataFrame({\n",
        "        'Model': ['Whisper', 'Vosk'],\n",
        "        'WER': [report['Whisper']['WER'], report['Vosk']['WER']]\n",
        "    })\n",
        "    st.bar_chart(chart_data.set_index('Model'))\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    > **WER (Word Error Rate)**: Lower is better. Whisper generally provides higher accuracy but requires more compute.\n",
        "    \"\"\")\n",
        "\n",
        "with tab4:\n",
        "    if st.session_state.processing_done:\n",
        "        st.header(\"Export Meeting Notes\")\n",
        "\n",
        "        json_str = export_as_json({\"segments\": st.session_state.segments, \"summary\": st.session_state.summary})\n",
        "        md_str = export_as_markdown(st.session_state.segments, st.session_state.summary)\n",
        "        csv_str = export_as_csv(st.session_state.segments)\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.download_button(\"Download JSON\", data=json_str, file_name=\"meeting_data.json\", mime=\"application/json\")\n",
        "        with col2:\n",
        "            st.download_button(\"Download Markdown\", data=md_str, file_name=\"meeting_summary.md\", mime=\"text/markdown\")\n",
        "        with col3:\n",
        "            st.download_button(\"Download CSV\", data=csv_str, file_name=\"transcript.csv\", mime=\"text/csv\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"Preview Markdown\")\n",
        "        st.markdown(md_str)\n",
        "    else:\n",
        "        st.warning(\"No data available for export. Please process an audio file first.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_uezPps4r9f",
        "outputId": "ceb4c52a-b325-4d2f-bd88-5b1445cf812a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "RESERVED_DOMAIN = None # Initialize RESERVED_DOMAIN\n",
        "\n",
        "def run_streamlit():\n",
        "    # Launch Streamlit on port 8501\n",
        "    subprocess.Popen(\n",
        "        [\n",
        "            \"streamlit\", \"run\", \"app.py\",\n",
        "            \"--server.port\", \"8501\",\n",
        "            \"--server.headless\", \"true\"\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Run Streamlit in background\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Give it a few seconds to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Create private tunnel (uses your authtoken from Cell 2)\n",
        "if RESERVED_DOMAIN:\n",
        "    # Requires paid ngrok plan and configured domain\n",
        "    tunnel = ngrok.connect(addr=8501, proto=\"http\", domain=RESERVED_DOMAIN)\n",
        "else:\n",
        "    tunnel = ngrok.connect(addr=8501, proto=\"http\")\n",
        "\n",
        "print(\"Varshini app URL:\", tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVb9U9kpXTnJ",
        "outputId": "b0e72983-027a-45cf-ddff-2dea357e1864"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Varshini app URL: https://mistilled-unimported-milagros.ngrok-free.dev\n"
          ]
        }
      ]
    }
  ]
}